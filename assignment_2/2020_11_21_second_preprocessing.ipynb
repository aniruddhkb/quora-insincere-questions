{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit760f76561f6442a8b7e1ff17f4562bdb",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/akb/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (28) have mixed types.Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "train_dset_df = pd.read_csv(\"./datasets/train.csv\")\n",
    "test_dset_df  = pd.read_csv(\"./datasets/test.csv\")\n",
    "\n",
    "preprocessing_df = pd.read_csv(\"./2020_11_21_categories.csv\")\n",
    "imputation_df = pd.read_csv(\"./2020_11_19_imputation_list.csv\")\n",
    "\n",
    "preprocessing_df.set_index(\"feature_name\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "source": [
    "## Dropping columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MachineIdentifier\n",
      "DefaultBrowsersIdentifier\n",
      "CityIdentifier\n",
      "OrganizationIdentifier\n",
      "PuaMode\n",
      "Census_ProcessorClass\n",
      "Census_OSArchitecture\n",
      "Census_IsFlightingInternal\n",
      "Census_ThresholdOptIn\n",
      "Census_FirmwareVersionIdentifier\n",
      "Census_IsWIMBootEnabled\n"
     ]
    }
   ],
   "source": [
    "for column in preprocessing_df.index:\n",
    "    if(preprocessing_df.loc[column, \"drop\"] == 1):\n",
    "        print(column)\n",
    "        train_dset_df.drop(axis=\"columns\", inplace=True, labels=[column])\n",
    "        test_dset_df.drop(axis=\"columns\", inplace=True, labels=[column])"
   ]
  },
  {
   "source": [
    "## Imputing null values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Whoops!\nWhoops!\nWhoops!\nWhoops!\nWhoops!\nWhoops!\nWhoops!\nWhoops!\nWhoops!\nWhoops!\nWhoops!\nWhoops!\nWhoops!\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(imputation_df)):\n",
    "    try:\n",
    "        imputation_df[\"value_to_fill\"][i] = int(imputation_df[\"value_to_fill\"][i])\n",
    "    except:\n",
    "        print(\"Whoops!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_df.set_index(\"col_name\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in imputation_df.index:\n",
    "    train_dset_df[column].fillna(imputation_df.value_to_fill[column], inplace=True)\n",
    "    test_dset_df[column].fillna(imputation_df.value_to_fill[column], inplace=True)\n"
   ]
  },
  {
   "source": [
    "## \"Custom\" preprocessing some columns before one-hot encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_encode_columns = list(preprocessing_df[preprocessing_df.custom_encode == 1].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['SmartScreen',\n",
       " 'Census_PrimaryDiskTypeName',\n",
       " 'Census_InternalPrimaryDisplayResolutionHorizontal',\n",
       " 'Census_InternalPrimaryDisplayResolutionVertical']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "custom_encode_columns"
   ]
  },
  {
   "source": [
    "### Smartscreen"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['off', 'RequireAdmin', 'ExistsNotSet', 'Off', 'Warn', 'Prompt',\n",
       "       'Block', '&#x02;', '&#x01;', 'On', 'on', 'requireadmin', 'prompt',\n",
       "       'Enabled'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train_dset_df.SmartScreen.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/akb/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/home/akb/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\n/home/akb/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_dset_df.SmartScreen = train_dset_df.SmartScreen.apply(lambda x: x.lower())\n",
    "train_dset_df.SmartScreen[train_dset_df.SmartScreen == \"enabled\"] = \"on\"\n",
    "train_dset_df.SmartScreen[train_dset_df.SmartScreen == '&#x02;'] = \"off\"\n",
    "train_dset_df.SmartScreen[train_dset_df.SmartScreen == '&#x01;'] = \"off\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/akb/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/home/akb/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\n/home/akb/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "test_dset_df.SmartScreen = test_dset_df.SmartScreen.apply(lambda x: x.lower())\n",
    "test_dset_df.SmartScreen[test_dset_df.SmartScreen == \"enabled\"] = \"on\"\n",
    "test_dset_df.SmartScreen[test_dset_df.SmartScreen == '&#x02;'] = \"off\"\n",
    "test_dset_df.SmartScreen[test_dset_df.SmartScreen == '&#x01;'] = \"off\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['off', 'requireadmin', 'existsnotset', 'warn', 'block', 'prompt',\n",
       "       'on'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "test_dset_df.SmartScreen.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Census_PrimaryDiskTypeName"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/akb/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n/home/akb/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n"
     ]
    }
   ],
   "source": [
    "train_dset_df.Census_PrimaryDiskTypeName[train_dset_df.Census_PrimaryDiskTypeName == \"Unspecified\"] = \"UNKNOWN\"\n",
    "test_dset_df.Census_PrimaryDiskTypeName[test_dset_df.Census_PrimaryDiskTypeName == \"Unspecified\"] = \"UNKNOWN\""
   ]
  },
  {
   "source": [
    "### Census_InternalPrimaryDisplayResolutionHorizontal and Census_InternalPrimaryDisplayResolutionVertical"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod=  list(train_dset_df.Census_InternalPrimaryDisplayResolutionHorizontal.to_numpy() * train_dset_df.Census_InternalPrimaryDisplayResolutionVertical.to_numpy())\n",
    "quot = list(train_dset_df.Census_InternalPrimaryDisplayResolutionHorizontal.to_numpy()/ train_dset_df.Census_InternalPrimaryDisplayResolutionVertical.to_numpy())\n",
    "train_dset_df.Census_InternalPrimaryDisplayResolutionHorizontal = prod\n",
    "train_dset_df.Census_InternalPrimaryDisplayResolutionVertical = quot\n",
    "train_dset_df.rename(mapper={\"Census_InternalPrimaryDisplayResolutionHorizontal\": \"pixels\", \"Census_InternalPrimaryDisplayResolutionVertical\": \"aspect_ratio\"}, inplace=True, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod=  list(test_dset_df.Census_InternalPrimaryDisplayResolutionHorizontal.to_numpy() * test_dset_df.Census_InternalPrimaryDisplayResolutionVertical.to_numpy())\n",
    "quot = list(test_dset_df.Census_InternalPrimaryDisplayResolutionHorizontal.to_numpy()/ test_dset_df.Census_InternalPrimaryDisplayResolutionVertical.to_numpy())\n",
    "test_dset_df.Census_InternalPrimaryDisplayResolutionHorizontal = prod\n",
    "test_dset_df.Census_InternalPrimaryDisplayResolutionVertical = quot\n",
    "test_dset_df.rename(mapper={\"Census_InternalPrimaryDisplayResolutionHorizontal\": \"pixels\", \"Census_InternalPrimaryDisplayResolutionVertical\": \"aspect_ratio\"}, inplace=True, axis=\"columns\")"
   ]
  },
  {
   "source": [
    "## One-hot encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_one_hot_encode = list(preprocessing_df[preprocessing_df.one_hot_encode == 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_one_hot_encode.extend([\"Census_PrimaryDiskTypeName\", \"SmartScreen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_columns_expected = 0\n",
    "for column in columns_to_one_hot_encode:\n",
    "    number_of_columns_expected += train_dset_df[column].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "65398"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "number_of_columns_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns_to_ohe = train_dset_df.loc[:, columns_to_one_hot_encode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_columns_to_ohe = test_dset_df.loc[:,columns_to_one_hot_encode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_not_ohe = [column for column in test_dset_df.columns if column not in columns_to_one_hot_encode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns_to_not_ohe = train_dset_df.loc[:,columns_to_not_ohe]\n",
    "test_columns_to_not_ohe = test_dset_df.loc[:, columns_to_not_ohe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "ohe.fit(train_columns_to_ohe.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ohe_columns_X = ohe.transform(train_columns_to_ohe.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<567730x65391 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 25547850 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "train_ohe_columns_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ohe_columns_X = ohe.transform(test_columns_to_ohe.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<243313x65391 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10935682 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "test_ohe_columns_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_not_ohe_columns_X = scipy.sparse.csr.csr_matrix(train_columns_to_not_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_not_ohe_columns_X = scipy.sparse.csr.csr_matrix(test_columns_to_not_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = scipy.sparse.hstack([train_not_ohe_columns_X,train_ohe_columns_X])\n",
    "test_X = scipy.sparse.hstack([test_not_ohe_columns_X,test_ohe_columns_X])\n",
    "train_Y = train_dset_df.HasDetections.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns_to_not_ohe = None \n",
    "train_columns_to_ohe = None \n",
    "test_columns_to_not_ohe = None \n",
    "test_columns_to_ohe = None \n",
    "test_ohe_columns_X = None \n",
    "test_not_ohe_columns_X = None \n",
    "train_ohe_columns_X = None \n",
    "train_not_ohe_columns_X = None \n",
    "train_dset_df = None \n",
    "test_dset_df = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.tocsr()\n",
    "test_X = test_X.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.data = np.nan_to_num(train_X.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.data = np.nan_to_num(test_X.data)"
   ]
  },
  {
   "source": [
    "## First models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(model, X, y):\n",
    "    yhat = model.predict(X)\n",
    "    print(\"ROC AUC SCORE:\", roc_auc_score(y, yhat))\n",
    "    print(\"F1 SCORE:\", f1_score(y, yhat))\n",
    "    plot_confusion_matrix(model, X, y)\n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "### BernoulliNB BernoulliNB(class_prior=(0.5,0.5))\n",
    "TRAINING SCORES:\n",
    "ROC AUC SCORE: 0.60\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=10)\n",
    "# bnb = BernoulliNB(class_prior=(0.3,0.7))\n",
    "# for train_indices, test_indices in kf.split(train_X):\n",
    "#     train_split_X = train_X[train_indices,:]\n",
    "#     test_split_X = train_X[test_indices,:]\n",
    "#     train_split_Y = train_Y[train_indices]\n",
    "#     test_split_Y = train_Y[test_indices]\n",
    "#     bnb.fit(train_split_X, train_split_Y)\n",
    "#     print(\"\\n\\nTRAINING SCORES:\")\n",
    "#     describe(bnb, train_split_X, train_split_Y)\n",
    "\n",
    "#     print(\"\\nTESTING SCORES:\")\n",
    "#     describe(bnb, test_split_X, test_split_Y)    "
   ]
  },
  {
   "source": [
    "### Test writing from BernoulliNB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bnb = BernoulliNB(class_prior=(0.5,0.5))\n",
    "# bnb.fit(train_X, train_Y)\n",
    "# test_Yhat = bnb.predict(test_X)\n",
    "# test_dset_df  = pd.read_csv(\"./datasets/test.csv\")\n",
    "# test_dset_df = test_dset_df.loc[:,[\"MachineIdentifier\"]]\n",
    "# test_dset_df[\"HasDetections\"] = np.array(test_Yhat, dtype=\"int64\")\n",
    "# test_dset_df.to_csv(\"AKB2020_11_21_output.csv\", index=False)\n"
   ]
  },
  {
   "source": [
    "## Adaboost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=10)\n",
    "# adbc = AdaBoostClassifier(n_estimators = 100, learning_rate=1)\n",
    "# for train_indices, test_indices in kf.split(train_X):\n",
    "#     train_split_X = train_X[train_indices,:]\n",
    "#     test_split_X = train_X[test_indices,:]\n",
    "#     train_split_Y = train_Y[train_indices]\n",
    "#     test_split_Y = train_Y[test_indices]\n",
    "#     adbc.fit(train_split_X, train_split_Y)\n",
    "#     print(\"\\n\\nTRAINING SCORES:\")\n",
    "#     describe(adbc, train_split_X, train_split_Y)\n",
    "\n",
    "#     print(\"\\nTESTING SCORES:\")\n",
    "#     describe(adbc, test_split_X, test_split_Y)    "
   ]
  },
  {
   "source": [
    "## GradientBoostedClassifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=10)\n",
    "# gdbc = GradientBoostingClassifier(n_estimators = 100, learning_rate=1, verbose=2)\n",
    "# for train_indices, test_indices in kf.split(train_X):\n",
    "#     train_split_X = train_X[train_indices,:]\n",
    "#     test_split_X = train_X[test_indices,:]\n",
    "#     train_split_Y = train_Y[train_indices]\n",
    "#     test_split_Y = train_Y[test_indices]\n",
    "#     gdbc.fit(train_split_X, train_split_Y)\n",
    "#     print(\"\\n\\nTRAINING SCORES:\")\n",
    "#     describe(gdbc, train_split_X, train_split_Y)\n",
    "\n",
    "#     print(\"\\nTESTING SCORES:\")\n",
    "#     describe(gdbc, test_split_X, test_split_Y)    "
   ]
  },
  {
   "source": [
    "# First look at Imblearn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler()\n",
    "gdbc = GradientBoostingClassifier(n_estimators = 100, learning_rate=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=10)\n",
    "# for train_indices, test_indices in kf.split(train_X):\n",
    "#     train_split_X = train_X[train_indices,:]\n",
    "#     test_split_X = train_X[test_indices,:]\n",
    "#     train_split_Y = train_Y[train_indices]\n",
    "#     test_split_Y = train_Y[test_indices]\n",
    "#     train_split_X, train_split_Y = ros.fit_resample(train_split_X, train_split_Y)\n",
    "#     gdbc.fit(train_split_X, train_split_Y)\n",
    "#     print(\"\\n\\nTRAINING SCORES:\")\n",
    "#     describe(gdbc, train_split_X, train_split_Y)\n",
    "\n",
    "#     print(\"\\nTESTING SCORES:\")\n",
    "#     describe(gdbc, test_split_X, test_split_Y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3020           13.74m\n",
      "         2           1.2934           13.46m\n",
      "         3           1.2874           13.21m\n",
      "         4           1.2823           13.00m\n",
      "         5           1.2794           12.92m\n",
      "         6           1.2753           12.73m\n",
      "         7           1.2729           12.65m\n",
      "         8           1.2710           12.52m\n",
      "         9           1.2694           12.34m\n",
      "        10           1.2679           12.15m\n",
      "        11           1.2666           11.94m\n",
      "        12           1.2655           11.77m\n",
      "        13           1.2646           11.59m\n",
      "        14           1.2635           11.43m\n",
      "        15           1.2621           11.27m\n",
      "        16           1.2612           11.11m\n",
      "        17           1.2605           10.96m\n",
      "        18           1.2598           10.81m\n",
      "        19           1.2588           10.67m\n",
      "        20           1.2577           10.51m\n",
      "        21           1.2566           10.37m\n",
      "        22           1.2546           10.22m\n",
      "        23           1.2539           10.08m\n",
      "        24           1.2526            9.94m\n",
      "        25           1.2519            9.81m\n",
      "        26           1.2513            9.61m\n",
      "        27           1.2508            9.39m\n",
      "        28           1.2503            9.19m\n",
      "        29           1.2497            8.99m\n",
      "        30           1.2491            8.78m\n",
      "        31           1.2487            8.56m\n",
      "        32           1.2482            8.37m\n",
      "        33           1.2477            8.18m\n",
      "        34           1.2472            7.99m\n",
      "        35           1.2468            7.81m\n",
      "        36           1.2464            7.63m\n",
      "        37           1.2459            7.46m\n",
      "        38           1.2454            7.29m\n",
      "        39           1.2450            7.12m\n",
      "        40           1.2445            6.96m\n",
      "        41           1.2438            6.80m\n",
      "        42           1.2431            6.65m\n",
      "        43           1.2428            6.50m\n",
      "        44           1.2424            6.34m\n",
      "        45           1.2420            6.20m\n",
      "        46           1.2417            6.05m\n",
      "        47           1.2412            5.92m\n",
      "        48           1.2404            5.80m\n",
      "        49           1.2392            5.67m\n",
      "        50           1.2389            5.53m\n",
      "        51           1.2383            5.40m\n",
      "        52           1.2379            5.28m\n",
      "        53           1.2374            5.15m\n",
      "        54           1.2371            5.02m\n",
      "        55           1.2368            4.89m\n",
      "        56           1.2366            4.76m\n",
      "        57           1.2363            4.63m\n",
      "        58           1.2360            4.51m\n",
      "        59           1.2357            4.38m\n",
      "        60           1.2354            4.26m\n",
      "        61           1.2352            4.14m\n",
      "        62           1.2345            4.03m\n",
      "        63           1.2339            3.91m\n",
      "        64           1.2333            3.80m\n",
      "        65           1.2331            3.68m\n",
      "        66           1.2325            3.57m\n",
      "        67           1.2321            3.45m\n",
      "        68           1.2319            3.34m\n",
      "        69           1.2317            3.22m\n",
      "        70           1.2314            3.11m\n",
      "        71           1.2312            3.00m\n",
      "        72           1.2310            2.88m\n",
      "        73           1.2308            2.77m\n",
      "        74           1.2304            2.67m\n",
      "        75           1.2302            2.56m\n",
      "        76           1.2300            2.45m\n",
      "        77           1.2298            2.34m\n",
      "        78           1.2297            2.23m\n",
      "        79           1.2294            2.13m\n",
      "        80           1.2292            2.02m\n",
      "        81           1.2290            1.92m\n",
      "        82           1.2288            1.81m\n",
      "        83           1.2286            1.71m\n",
      "        84           1.2283            1.61m\n",
      "        85           1.2281            1.50m\n",
      "        86           1.2279            1.40m\n",
      "        87           1.2277            1.30m\n",
      "        88           1.2276            1.20m\n",
      "        89           1.2274            1.10m\n",
      "        90           1.2267           59.79s\n",
      "        91           1.2264           53.74s\n",
      "        92           1.2261           47.69s\n",
      "        93           1.2259           41.65s\n",
      "        94           1.2258           35.63s\n",
      "        95           1.2255           29.64s\n",
      "        96           1.2253           23.67s\n",
      "        97           1.2251           17.73s\n",
      "        98           1.2249           11.79s\n",
      "        99           1.2247            5.89s\n",
      "       100           1.2246            0.00s\n"
     ]
    }
   ],
   "source": [
    "resampled_train_X, resampled_train_Y = ros.fit_resample(train_X, train_Y)\n",
    "gdbc.fit(resampled_train_X, resampled_train_Y)\n",
    "\n",
    "test_Yhat = np.round(gdbc.predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/akb/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (28) have mixed types.Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "test_dset_df  = pd.read_csv(\"./datasets/test.csv\")\n",
    "test_dset_df = test_dset_df.loc[:,[\"MachineIdentifier\"]]\n",
    "test_dset_df[\"HasDetections\"] = np.array(test_Yhat, dtype=\"int64\")\n",
    "test_dset_df.to_csv(\"AKB2020_11_22_output.csv\", index=False)"
   ]
  }
 ]
}