{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit760f76561f6442a8b7e1ff17f4562bdb",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Using Clustering Features\n",
    "\n",
    "using output of 2020_10_31_clustering_on_unique_word_embedings and based on 2020_10_19_further_svm_tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports and preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "train_dset_df = pd.read_csv(\"2020_10_19_train_dset_df_nostem_nostoprem.csv\")\n",
    "test_dset_df = pd.read_csv(\"2020_10_19_test_dset_df_nostem_nostoprem.csv\")\n",
    "train_dset_df[\"preprocessed_joined\"].fillna(\"\", inplace=True)\n",
    "test_dset_df[\"preprocessed_joined\"].fillna(\"\", inplace=True)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_dset_df[\"preprocessed_joined\"])\n",
    "sparse_train_x = vectorizer.transform(train_dset_df[\"preprocessed_joined\"])\n",
    "sparse_test_x  = vectorizer.transform(test_dset_df[\"preprocessed_joined\"])\n",
    "train_dset_y = train_dset_df[\"target\"].to_numpy()\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Adding the clustering features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTERS = 100 \n",
    "TRAIN_N_DATA_POINTS = sparse_train_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTERS_FOLDER = \"./outputs/2020_11_3_agglo_groups/\"\n",
    "FILE_STRING = \"2020_11_3_agglo_group_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_strings = []\n",
    "for i in range(100):\n",
    "    with open(CLUSTERS_FOLDER + FILE_STRING + str(i) +\".txt\") as file_handler:\n",
    "        group_strings.append(set([word[:-1] for word in file_handler.readlines()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'honest', 'interpreting', 'inform', 'clarify', 'circumstantial', 'contrary', 'regard', 'reprint', 'telephone', 'advises', 'associated', 'assertion', 'contradict', 'detail', 'guardian', 'proof', 'understood', 'interpol', 'conversations', 'headline', 'pointed', 'press', 'mistake', 'journalists', 'page', 'corroboration', 'confidential', 'daily', 'documentation', 'explanation', 'legal', 'please', 'bulletin', 'reported', 'strongly', 'agency', 'published', 'asking', 'corroborated', 'advice', 'scrutiny', 'understand', 'observer', 'commentary', 'arguments', 'consulate', 'cited', 'memo', 'call', 'mail', 'newspaper', 'incontrovertible', 'message', 'briefing', 'opinion', 'showing', 'disclosure', 'talked', 'contacted', 'wrong', 'changing', 'text', 'verify', 'authenticity', 'listen', 'observed', 'subject', 'quoting', 'columns', 'magazine', 'confirm', 'hears', 'relating', 'ask', 'exculpatory', 'interpretation', 'liked', 'opinions', 'thank', 'dossier', 'truly', 'attributed', 'interview', 'speakers', 'suggested', 'characterized', 'recalled', 'contact', 'confirmed', 'whereabouts', 'unidentified', 'evident', 'extensive', 'spokeswoman', 'publication', 'negative', 'profoundly', 'noted', 'verified', 'forwarded', 'articles', 'speaks', 'official', 'closely', 'column', 'wish', 'indicated', 'note', 'dear', 'interpreted', 'pointing', 'suggestions', 'truth', 'reading', 'clearly', 'correction', 'revealed', 'unnamed', 'publishing', 'editorial', 'interviewing', 'diplomats', 'issued', 'unclear', 'credible', 'absolutely', 'correct', 'reasoned', 'heard', 'defence', 'regarding', 'corroborating', 'stance', 'concerned', 'suggest', 'notifies', 'spokesperson', 'consult', 'conclusive', 'acknowledged', 'advised', 'facts', 'notified', 'anecdotal', 'divulge', 'reasoning', 'contradicting', 'telegraph', 'telling', 'wikipedia', 'explaining', 'interpret', 'concerning', 'irrefutable', 'unconfirmed', 'corrected', 'explain', 'reflect', 'anonymity', 'issue', 'matter', 'specify', 'question', 'speaking', 'advise', 'informed', 'statement', 'contradicts', 'article', 'conversation', 'describing', 'clarification', 'mention', 'exchanged', 'verbatim', 'notes', 'talk', 'anonymously', 'exchanging', 'defense', 'notify', 'alerting', 'afp', 'mentioning', 'contrast', 'unverified', 'asked', 'answered', 'write', 'argument', 'mistakes', 'eyewitness', 'likes', 'indicates', 'letter', 'listening', 'correspondence', 'attache', 'damning', 'unanswered', 'genuinely', 'embassy', 'incriminating', 'file', 'hear', 'liaison', 'indication', 'ministry', 'pertaining', 'remark', 'quote', 'rumsfeld', 'saying', 'consular', 'report', 'sketchy', 'comparing', 'spoke', 'suggests', 'phone', 'read', 'editorials', 'trend', 'indicating', 'disclose', 'definitive', 'pentagon', 'obtained', 'calling', 'alibi', 'indications', 'answering', 'publisher', 'spoken', 'xinhua', 'suggestion', 'speak', 'positive', 'assign', 'document', 'broadly', 'factual', 'writing', 'handwritten', 'suggesting', 'detailed', 'told', 'indicate', 'client', 'reflected', 'showed', 'answer', 'described', 'comment', 'informing', 'inquire', 'excused', 'files', 'newspapers', 'news', 'detailing', 'memos', 'copy', 'express', 'publish', 'spokesman', 'aware', 'interviewed', 'staff', 'circulated', 'transcript', 'deeply', 'actionable', 'veracity'}\n"
     ]
    }
   ],
   "source": [
    "print(group_strings[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_features = np.zeros((TRAIN_N_DATA_POINTS, N_CLUSTERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    qid  target  \\\n",
       "0  6f47b0f60633c2056455       0   \n",
       "1  d49b3966070b27bf07fc       0   \n",
       "2  6d5faa49380557c8ca7b       0   \n",
       "3  cebea75faa47388edcf5       0   \n",
       "4  2a7b76a679cadb0a016e       0   \n",
       "\n",
       "                                 preprocessed_joined  \n",
       "0  how can i reply to this comment india be poor ...  \n",
       "1  what do they use for transportation in ancient...  \n",
       "2  what be the most important provision of obama ...  \n",
       "3     at what age do most finns master english today  \n",
       "4  what be cheap place to live in india for one m...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>target</th>\n      <th>preprocessed_joined</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6f47b0f60633c2056455</td>\n      <td>0</td>\n      <td>how can i reply to this comment india be poor ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>d49b3966070b27bf07fc</td>\n      <td>0</td>\n      <td>what do they use for transportation in ancient...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6d5faa49380557c8ca7b</td>\n      <td>0</td>\n      <td>what be the most important provision of obama ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cebea75faa47388edcf5</td>\n      <td>0</td>\n      <td>at what age do most finns master english today</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2a7b76a679cadb0a016e</td>\n      <td>0</td>\n      <td>what be cheap place to live in india for one m...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train_dset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 100/100 [08:27<00:00,  5.07s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    for j in (range(len(train_dset_df))):\n",
    "        sentence_list = train_dset_df[\"preprocessed_joined\"][j].split()\n",
    "        for word in sentence_list:\n",
    "            if word in group_strings[i]:\n",
    "                extra_features[j][i] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_extra_features = csr.csr_matrix(extra_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<783673x54972 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8974499 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "sparse_train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sparse_train_x = hstack((sparse_train_x, sparse_extra_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<783673x55072 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12556371 stored elements in COOrdinate format>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "new_sparse_train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_train_x=new_sparse_train_x"
   ]
  },
  {
   "source": [
    "## LinearSVC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearSVC(C=0.0125, class_weight={0: 1, 1: 3.35})"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "svm = LinearSVC(penalty=\"l2\",dual=True,class_weight={0:1,1:3.35}, C=0.0125)\n",
    "svm.fit(sparse_train_x, train_dset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6510702983833189"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "train_dset_yhat = svm.predict(sparse_train_x)\n",
    "f1_score(train_dset_y, train_dset_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "22096 14401\n735222 48451\n"
     ]
    }
   ],
   "source": [
    "train_dset_df[\"yhat\"] = train_dset_yhat\n",
    "wrongs = train_dset_df[train_dset_df[\"target\"] != train_dset_df[\"yhat\"]]\n",
    "print(len(wrongs.groupby(by=\"target\").get_group(0)),len(wrongs.groupby(by=\"target\").get_group(1)))\n",
    "print(len(train_dset_df.groupby(by=\"target\").get_group(0)), len(train_dset_df.groupby(by=\"target\").get_group(1)))"
   ]
  },
  {
   "source": [
    "## Cross validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "15219"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfcv = KFold(n_splits=10, shuffle=True)\n",
    "train_f1_scores = []\n",
    "test_f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAINING AGAIN. 0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-bbc34284d1d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# print(\"TRAIN:\", train_index, \"TEST:\", test_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_train_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_train_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dset_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dset_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for train_index, test_index in kfcv.split(sparse_train_x):\n",
    "    print(\"TRAINING AGAIN.\", i)\n",
    "    i+=1\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    x_train, x_test = sparse_train_x[train_index], sparse_train_x[test_index]\n",
    "    y_train, y_test = train_dset_y[train_index], train_dset_y[test_index]\n",
    "    svm.fit(x_train, y_train)\n",
    "    train_yhat = svm.predict(x_train)\n",
    "    train_f1_score = f1_score(y_train, train_yhat)\n",
    "    test_yhat = svm.predict(x_test)\n",
    "    test_f1_score = f1_score(y_test, test_yhat)\n",
    "    n_y_one_and_yhat_zero = np.sum(np.logical_and(y_test == 1, test_yhat == 0).astype(int))\n",
    "    n_y_zero_and_yhat_one = np.sum(np.logical_and(y_test == 0, test_yhat == 1).astype(int))\n",
    "    print(\"Zeros wrong, ones wrong in test = \", n_y_zero_and_yhat_one,n_y_one_and_yhat_zero)\n",
    "    print(\"Test f1 score:\", test_f1_score)\n",
    "    print(\"Test precision score:\", precision_score(y_test, test_yhat))\n",
    "    print(\"Recall score:\", recall_score(y_test, test_yhat))\n",
    "    train_f1_scores.append(train_f1_score)\n",
    "    test_f1_scores.append(test_f1_score)\n",
    "    train_yhat = None \n",
    "    test_yhat = None \n",
    "    x_train = None \n",
    "    x_test = None \n",
    "    y_train = None \n",
    "    y_test = None \n",
    "    print(gc.collect())\n",
    "    print(gc.collect())\n",
    "    print(gc.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.6523289074840969,\n",
       " 0.6516767560295954,\n",
       " 0.6506225131562059,\n",
       " 0.6518062048448788,\n",
       " 0.650933804248943,\n",
       " 0.6507430884781336,\n",
       " 0.6511568288149716,\n",
       " 0.6511399538895055,\n",
       " 0.6521511634115348,\n",
       " 0.6512646797961126]"
      ]
     },
     "metadata": {},
     "execution_count": 332
    }
   ],
   "source": [
    "train_f1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.6165752351097179,\n",
       " 0.6120565330256706,\n",
       " 0.6215414073719483,\n",
       " 0.6137766275134381,\n",
       " 0.6193930139339568,\n",
       " 0.6165015206514274,\n",
       " 0.6122527737578389,\n",
       " 0.6165020337013365,\n",
       " 0.6074116965836712,\n",
       " 0.616070563148202]"
      ]
     },
     "metadata": {},
     "execution_count": 333
    }
   ],
   "source": [
    "test_f1_scores                                                                  "
   ]
  },
  {
   "source": [
    "## Testset write"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 522449 entries, 0 to 522448\nData columns (total 2 columns):\n #   Column               Non-Null Count   Dtype \n---  ------               --------------   ----- \n 0   qid                  522449 non-null  object\n 1   preprocessed_joined  522449 non-null  object\ndtypes: object(2)\nmemory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "sparse_test_x = vectorizer.transform(test_dset_df[\"preprocessed_joined\"])\n",
    "test_yhat = svm.predict(sparse_test_x)\n",
    "output_df = test_dset_df.copy()\n",
    "output_df.info()\n",
    "output_df[\"preprocessed_joined\"] = test_yhat\n",
    "output_df = output_df.rename(columns={\"qid\":\"qid\", \"preprocessed_joined\":\"target\"})\n",
    "output_df.target = output_df.target.apply(round)\n",
    "output_df.to_csv(\"./outputs/2020_10_28_a_testset_output.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}