{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit760f76561f6442a8b7e1ff17f4562bdb",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Threshold_Management\n",
    "\n",
    "\n",
    "-------------------------------------------------------------------\n",
    "\n",
    "----------------------------------------------------------------------\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports and functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSET_FOLDER_PATH = './dataset/quora/'\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "tqdm.pandas()\n",
    "import numpy as np\n",
    "train_dset_df = pd.read_csv(DSET_FOLDER_PATH + \"train.csv\")\n",
    "test_dset_df = pd.read_csv(DSET_FOLDER_PATH + \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def summarize(model, X, y):\n",
    "    yhat = np.round(model.predict(X))\n",
    "    print(\"F1 score:\", f1_score(y, yhat))\n",
    "    print(\"Precision:\", precision_score(y, yhat))\n",
    "    print(\"Recall:\", recall_score(y, yhat))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y, yhat))\n",
    "    return f1_score(y, yhat)\n",
    "\n",
    "def cross_validate(model, n_folds, X, y):\n",
    "    kfcv = StratifiedKFold(n_splits=n_folds)\n",
    "    i = 0\n",
    "    validation_f1_scores = []\n",
    "    for train_indices, test_indices in kfcv.split(X,y):\n",
    "        print(\"Round number\", i)\n",
    "        i += 1\n",
    "        trainset_X = X[train_indices,:]\n",
    "        testset_X  = X[test_indices,:]\n",
    "        trainset_y = y[train_indices]\n",
    "        testset_y  = y[test_indices]\n",
    "        model.fit(trainset_X, trainset_y)\n",
    "        print(\"\\n\\nTraining:\")\n",
    "        summarize(model,trainset_X, trainset_y)\n",
    "        print(\"Testing:\")\n",
    "        validation_f1_scores.append(summarize(model, testset_X, testset_y))\n",
    "        print((\"-\"*15))\n",
    "    validation_f1_scores = np.array(validation_f1_scores)\n",
    "    print(\"Mean validation f1 score:\", np.mean(validation_f1_scores))\n",
    "    print(\"Median validation f1 score:\", np.median(validation_f1_scores))"
   ]
  },
  {
   "source": [
    "## Vectorization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(lowercase=False, token_pattern=r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'\", ngram_range=(1,3))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = vectorizer.fit_transform(train_dset_df[\"question_text\"])\n",
    "train_y = train_dset_df[\"target\"].to_numpy()"
   ]
  },
  {
   "source": [
    "## Model Cross-Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Separator:\n",
    "    '''\n",
    "    Using the decision_function of the first model, fit a logistic curve to the output of the first model. \n",
    "    '''\n",
    "    def __init__(self, decision_model, logistic_model):\n",
    "        self.decision_model = decision_model \n",
    "        self.logistic_model = logistic_model \n",
    "    def fit(self,X, y):\n",
    "        print(\"Fitting the base model.\")\n",
    "        self.decision_model.fit(X, y)\n",
    "        print(\"Fitting the intermediate\")\n",
    "        intermediate = self.decision_model.decision_function(X).reshape((-1,1))\n",
    "        self.logistic_model.fit(intermediate, y)\n",
    "    def predict(self, X):\n",
    "        intermediate = self.decision_model.decision_function(X).reshape((-1,1))\n",
    "        return self.logistic_model.predict(intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvm = LinearSVC(C=0.24, class_weight={0:1,1:1}, max_iter=10000)\n",
    "logistic = LogisticRegression(C=1, class_weight = {0:1,1:3.8}, max_iter=1000, n_jobs=6)\n",
    "model=Logistic_Separator(lsvm, logistic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Round number 0\n",
      "Fitting the base model.\n",
      "Fitting the intermediate\n",
      "\n",
      "\n",
      "Training:\n",
      "F1 score: 0.8935220935220936\n",
      "Precision: 0.8392634081476408\n",
      "Recall: 0.9552813832958768\n",
      "Confusion matrix:\n",
      "[[653721   7978]\n",
      " [  1950  41656]]\n",
      "Testing:\n",
      "F1 score: 0.6338819751103975\n",
      "Precision: 0.6169173666731783\n",
      "Recall: 0.6518059855521156\n",
      "Confusion matrix:\n",
      "[[71562  1961]\n",
      " [ 1687  3158]]\n",
      "---------------\n",
      "Round number 1\n",
      "Fitting the base model.\n",
      "Fitting the intermediate\n",
      "\n",
      "\n",
      "Training:\n",
      "F1 score: 0.8940941885271384\n",
      "Precision: 0.8394765978862607\n",
      "Recall: 0.9563133513736641\n",
      "Confusion matrix:\n",
      "[[653725   7974]\n",
      " [  1905  41701]]\n",
      "Testing:\n",
      "F1 score: 0.6337506259389084\n",
      "Precision: 0.6155642023346304\n",
      "Recall: 0.6530443756449948\n",
      "Confusion matrix:\n",
      "[[71547  1976]\n",
      " [ 1681  3164]]\n",
      "---------------\n",
      "Round number 2\n",
      "Fitting the base model.\n",
      "Fitting the intermediate\n",
      "\n",
      "\n",
      "Training:\n",
      "F1 score: 0.8934103748807393\n",
      "Precision: 0.8388018841338218\n",
      "Recall: 0.95562435500516\n",
      "Confusion matrix:\n",
      "[[653692   8008]\n",
      " [  1935  41670]]\n",
      "Testing:\n",
      "F1 score: 0.6272248185343542\n",
      "Precision: 0.6052581078487814\n",
      "Recall: 0.6508460586050351\n",
      "Confusion matrix:\n",
      "[[71465  2057]\n",
      " [ 1692  3154]]\n",
      "---------------\n",
      "Round number 3\n",
      "Fitting the base model.\n",
      "Fitting the intermediate\n",
      "\n",
      "\n",
      "Training:\n",
      "F1 score: 0.8930756947346987\n",
      "Precision: 0.8382994990242038\n",
      "Recall: 0.9555107095353851\n",
      "Confusion matrix:\n",
      "[[653663   8037]\n",
      " [  1940  41666]]\n",
      "Testing:\n",
      "F1 score: 0.6283831019674423\n",
      "Precision: 0.6087461300309598\n",
      "Recall: 0.6493292053663571\n",
      "Confusion matrix:\n",
      "[[71500  2022]\n",
      " [ 1699  3146]]\n",
      "---------------\n",
      "Round number 4\n",
      "Fitting the base model.\n",
      "Fitting the intermediate\n",
      "\n",
      "\n",
      "Training:\n",
      "F1 score: 0.8935344919957997\n",
      "Precision: 0.8385961383748994\n",
      "Recall: 0.9561757556299592\n",
      "Confusion matrix:\n",
      "[[653675   8025]\n",
      " [  1911  41695]]\n",
      "Testing:\n",
      "F1 score: 0.6350997380616563\n",
      "Precision: 0.6203503247392246\n",
      "Recall: 0.6505675954592364\n",
      "Confusion matrix:\n",
      "[[71593  1929]\n",
      " [ 1693  3152]]\n",
      "---------------\n",
      "Round number 5\n",
      "Fitting the base model.\n",
      "Fitting the intermediate\n",
      "\n",
      "\n",
      "Training:\n",
      "F1 score: 0.8932690246516614\n",
      "Precision: 0.8385519378597014\n",
      "Recall: 0.9556253726551392\n",
      "Confusion matrix:\n",
      "[[653677   8023]\n",
      " [  1935  41671]]\n",
      "Testing:\n",
      "F1 score: 0.6308243727598566\n",
      "Precision: 0.6093479515291402\n",
      "Recall: 0.6538699690402476\n",
      "Confusion matrix:\n",
      "[[71491  2031]\n",
      " [ 1677  3168]]\n",
      "---------------\n",
      "Round number 6\n",
      "Fitting the base model.\n",
      "Fitting the intermediate\n",
      "\n",
      "\n",
      "Training:\n",
      "F1 score: 0.8934573829531812\n",
      "Precision: 0.8387603139464681\n",
      "Recall: 0.955785901022795\n",
      "Confusion matrix:\n",
      "[[653688   8012]\n",
      " [  1928  41678]]\n",
      "Testing:\n",
      "F1 score: 0.6316425120772947\n",
      "Precision: 0.6163818503241013\n",
      "Recall: 0.6476780185758514\n",
      "Confusion matrix:\n",
      "[[71569  1953]\n",
      " [ 1707  3138]]\n",
      "---------------\n",
      "Round number 7\n",
      "Fitting the base model.\n",
      "Fitting the intermediate\n",
      "\n",
      "\n",
      "Training:\n",
      "F1 score: 0.8931381165727024\n",
      "Precision: 0.8384448200917652\n",
      "Recall: 0.9554648442874834\n",
      "Confusion matrix:\n",
      "[[653672   8028]\n",
      " [  1942  41664]]\n",
      "Testing:\n",
      "F1 score: 0.6206896551724137\n",
      "Precision: 0.5985051743963204\n",
      "Recall: 0.6445820433436532\n",
      "Confusion matrix:\n",
      "[[71427  2095]\n",
      " [ 1722  3123]]\n",
      "---------------\n",
      "Round number 8\n",
      "Fitting the base model.\n",
      "Fitting the intermediate\n",
      "\n",
      "\n",
      "Training:\n",
      "F1 score: 0.8935112254192789\n",
      "Precision: 0.8386610070610956\n",
      "Recall: 0.9560381598862542\n",
      "Confusion matrix:\n",
      "[[653680   8020]\n",
      " [  1917  41689]]\n",
      "Testing:\n",
      "F1 score: 0.6348314606741572\n",
      "Precision: 0.6176068709740387\n",
      "Recall: 0.6530443756449948\n",
      "Confusion matrix:\n",
      "[[71563  1959]\n",
      " [ 1681  3164]]\n",
      "---------------\n",
      "Round number 9\n",
      "Fitting the base model.\n",
      "Fitting the intermediate\n",
      "\n",
      "\n",
      "Training:\n",
      "F1 score: 0.8935216943920425\n",
      "Precision: 0.838820688267257\n",
      "Recall: 0.9558546988946476\n",
      "Confusion matrix:\n",
      "[[653691   8009]\n",
      " [  1925  41681]]\n",
      "Testing:\n",
      "F1 score: 0.6220647773279352\n",
      "Precision: 0.6103277060575968\n",
      "Recall: 0.6342621259029928\n",
      "Confusion matrix:\n",
      "[[71560  1962]\n",
      " [ 1772  3073]]\n",
      "---------------\n",
      "Mean validation f1 score: 0.6298393037624417\n",
      "Median validation f1 score: 0.6312334424185757\n"
     ]
    }
   ],
   "source": [
    "cross_validate(model, 10, train_X, train_y)"
   ]
  },
  {
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(lowercase=False, token_pattern=r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'\", ngram_range=(1,3))\n",
    "\n",
    "lsvm = LinearSVC(C=0.24, class_weight={0:1,1:1}, max_iter=10000)\n",
    "\n",
    "logistic = LogisticRegression(C=1, class_weight = {0:1,1:3.8}, max_iter=1000, n_jobs=6)\n",
    "\n",
    "model=Logistic_Separator(lsvm, logistic)\n",
    "\n",
    "\n",
    "trigrams\n",
    "\n",
    "Mean validation f1 score: 0.633484221217779\n",
    "\n",
    "Median validation f1 score: 0.633362960290482"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Testset Write"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting the base model.\n",
      "Fitting the intermediate\n"
     ]
    }
   ],
   "source": [
    "test_X  = vectorizer.transform(test_dset_df[\"question_text\"])\n",
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 522449 entries, 0 to 522448\nData columns (total 2 columns):\n #   Column         Non-Null Count   Dtype \n---  ------         --------------   ----- \n 0   qid            522449 non-null  object\n 1   question_text  522449 non-null  object\ndtypes: object(2)\nmemory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "test_yhat = model.predict(test_X)\n",
    "output_df = test_dset_df.copy()\n",
    "output_df.info()\n",
    "output_df.drop(inplace=True, axis=1, labels=\"question_text\")\n",
    "output_df[\"preprocessed_joined\"] = test_yhat\n",
    "output_df = output_df.rename(columns={\"qid\":\"qid\", \"preprocessed_joined\":\"target\"})\n",
    "output_df.target = output_df.target.apply(round)\n",
    "output_df.to_csv(\"./outputs/2020_11_28_c_testset_output.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                         qid  target\n",
       "0       f56a9a31974dc66186e8       0\n",
       "1       d957c3758060f45da303       0\n",
       "2       ad822d5abaedb9e247b9       0\n",
       "3       4e979c23eeb6a4bd1f2e       0\n",
       "4       333cc031262566b8da49       0\n",
       "...                      ...     ...\n",
       "522444  e8e6aa5226f36c27fe41       0\n",
       "522445  015fd068afcb9d0b4007       0\n",
       "522446  9f0ef49eff6a3ff9e735       0\n",
       "522447  d6b02f52f76dc4c22afd       0\n",
       "522448  132ef601b08de269aee9       0\n",
       "\n",
       "[522449 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f56a9a31974dc66186e8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>d957c3758060f45da303</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ad822d5abaedb9e247b9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4e979c23eeb6a4bd1f2e</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>333cc031262566b8da49</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>522444</th>\n      <td>e8e6aa5226f36c27fe41</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>522445</th>\n      <td>015fd068afcb9d0b4007</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>522446</th>\n      <td>9f0ef49eff6a3ff9e735</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>522447</th>\n      <td>d6b02f52f76dc4c22afd</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>522448</th>\n      <td>132ef601b08de269aee9</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>522449 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}