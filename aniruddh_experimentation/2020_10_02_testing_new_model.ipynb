{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit760f76561f6442a8b7e1ff17f4562bdb",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSET_FOLDER_PATH = './dataset/quora/'\n",
    "GLOVE_FOLDER_PATH = './embeddings/glove/'\n",
    "CORPUS_FOLDER_PATH = './corpi/'\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt  \n",
    "import wordcloud as wc \n",
    "import seaborn as sns \n",
    "import nltk\n",
    "import re\n",
    "import contractions\n",
    "import symspellpy\n",
    "train_dset_df = pd.read_csv(DSET_FOLDER_PATH + \"train.csv\")\n",
    "from tqdm import tqdm \n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, path_to_words_corpus):\n",
    "        self.sym_spell = symspellpy.SymSpell()\n",
    "        self.sym_spell.create_dictionary(path_to_words_corpus)\n",
    "        self.tokenizer = nltk.tokenize.RegexpTokenizer(r\"\\w+\")\n",
    "        self.stopwords_corpus = set(nltk.corpus.stopwords.words())\n",
    "        self.stemmer = nltk.stem.PorterStemmer()\n",
    "    def preprocess(self,sentence):\n",
    "        sentence = sentence.lower()\n",
    "        sentence = re.sub(r\"\\d+\", \"\", sentence)\n",
    "        sentence = contractions.fix(sentence)\n",
    "        sentence = self.tokenizer.tokenize(sentence)\n",
    "        sentence = [word for word in sentence if not word in self.stopwords_corpus]\n",
    "        sentence = [self.stemmer.stem(word) for word in sentence]\n",
    "        sentence = [self.sym_spell.lookup(word, 0, include_unknown=True)[0].term for word in sentence]\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dset_df = pd.read_csv(DSET_FOLDER_PATH + \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(CORPUS_FOLDER_PATH + \"words_alpha.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 522449/522449 [04:43&lt;00:00, 1840.47it/s]\n"
    }
   ],
   "source": [
    "test_dset_df[\"preprocessed\"] = test_dset_df[\"question_text\"].progress_apply(preprocessor.preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.PreprocessingEmbedding20200928 as pped \n",
    "embedder = pped.Glove_Embedder(GLOVE_FOLDER_PATH + \"glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 522449/522449 [00:06&lt;00:00, 82609.84it/s]\n"
    }
   ],
   "source": [
    "test_dset_df[\"vectorized\"] = test_dset_df[\"preprocessed\"].progress_apply(embedder.get_embedding_for_sentence)\n",
    "\n",
    "X = np.array(test_dset_df.vectorized.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_model = joblib.load(\"./2020_10_02_new_model.joblib\")\n",
    "svc = pickle.loads(pickled_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = svc.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0, 0, 1, ..., 1, 0, 1])"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dset_df.question_text = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dset_df = test_dset_df.rename(columns={\"qid\":\"qid\", \"question_text\":\"target\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dset_df = test_dset_df.drop(labels=\"preprocessed\", axis=\"columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dset_df = test_dset_df.drop(labels=\"vectorized\", axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dset_df.to_csv(\"2020_10_03_testset_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}