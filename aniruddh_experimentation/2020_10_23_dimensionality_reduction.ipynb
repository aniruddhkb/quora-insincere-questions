{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit760f76561f6442a8b7e1ff17f4562bdb",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Dimensionality Reduction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The reason I have returned to dimensionality reduction is because it is simply not possible to handle the current scenario for the nonlinear SVCs.\n",
    "\n",
    "Update: Threshold of 100 occurences seems to have favorable results. Dimension reduces to 5900 with only a 0.05 decrease in F1 score (test, train)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Test f1 score during crossval:\n",
    "\n",
    " 0.6193501542929751,\n",
    " 0.6124941286989197,\n",
    " 0.6131977784053468,\n",
    " 0.6122831692451945,\n",
    " 0.6105302118996947,\n",
    " 0.6111627906976744,\n",
    " 0.6039510818438383,\n",
    " 0.6179420505200595,\n",
    " 0.610534194031247,\n",
    " 0.6130737134909596\n",
    "\n",
    " Train f1 score:\n",
    " 0.6475649945075064"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports and preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gc\n",
    "from tqdm import tqdm \n",
    "tqdm.pandas()\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "train_dset_df = pd.read_csv(\"2020_10_19_train_dset_df_nostem_nostoprem.csv\")\n",
    "test_dset_df = pd.read_csv(\"2020_10_19_test_dset_df_nostem_nostoprem.csv\")\n",
    "train_dset_df[\"preprocessed_joined\"].fillna(\"\", inplace=True)\n",
    "test_dset_df[\"preprocessed_joined\"].fillna(\"\", inplace=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(train_dset_df[\"preprocessed_joined\"])\n",
    "original_sparse_train_x = vectorizer.transform(train_dset_df[\"preprocessed_joined\"])\n",
    "original_sparse_test_x  = vectorizer.transform(test_dset_df[\"preprocessed_joined\"])\n",
    "train_dset_y = train_dset_df[\"target\"].to_numpy()\n",
    "\n",
    "def summarize(y, yhat):\n",
    "    '''\n",
    "    y and yhat are both 1-dimensional ndarrays where every entry is either 0 or 1. \n",
    "    y and yhat must have the same size \n",
    "    '''\n",
    "    print(\"Number of zeros in y:\", np.sum( (y == 0).astype(int) ))\n",
    "    print(\" Number of ones in y:\", np.sum((y == 1).astype(int)))\n",
    "    print(\"            F1 score:\", f1_score(y, yhat))\n",
    "    print(\" # of zeros wrong yh:\", np.sum(np.logical_and(y == 0, yhat == 1).astype(int)))\n",
    "    print(\"  # of ones wrong yh:\", np.sum(np.logical_and(y == 1, yhat == 0).astype(int)))\n"
   ]
  },
  {
   "source": [
    "## Dimensionality reduction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 54972/54972 [00:50<00:00, 1078.46it/s]\n"
     ]
    }
   ],
   "source": [
    "original_sparse_train_x_csc = original_sparse_train_x.tocsc()\n",
    "THRESHOLD = 100\n",
    "columns_to_keep = []\n",
    "for column_id in tqdm(range(original_sparse_train_x_csc.shape[1])):\n",
    "    if np.sum((original_sparse_train_x_csc[:,column_id] > 0).astype(int)) > THRESHOLD:\n",
    "        columns_to_keep.append(column_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "54972"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "original_sparse_train_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5600"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "len(columns_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_train_x = original_sparse_train_x[:,columns_to_keep]"
   ]
  },
  {
   "source": [
    "## LinearSVM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight={0: 1, 1: 2.9})"
      ]
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "svm = LinearSVC(penalty=\"l2\",dual=True,class_weight={0:1,1:2.9}, C=1)\n",
    "svm.fit(sparse_train_x, train_dset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of zeros in y: 735222\n",
      " Number of ones in y: 48451\n",
      "            F1 score: 0.601800142015468\n",
      " # of zeros wrong yh: 24405\n",
      "  # of ones wrong yh: 17093\n"
     ]
    }
   ],
   "source": [
    "train_dset_yhat = svm.predict(sparse_train_x)\n",
    "summarize(train_dset_y, train_dset_yhat)"
   ]
  },
  {
   "source": [
    "## Cross validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfcv = KFold(n_splits=10, shuffle=True)\n",
    "train_f1_scores = []\n",
    "test_f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAINING AGAIN. 0\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 1\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 2\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 3\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 4\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 5\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 6\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 7\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 8\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 9\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for train_index, test_index in kfcv.split(sparse_train_x):\n",
    "    print(\"TRAINING AGAIN.\", i)\n",
    "    i+=1\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    x_train, x_test = sparse_train_x[train_index], sparse_train_x[test_index]\n",
    "    y_train, y_test = train_dset_y[train_index], train_dset_y[test_index]\n",
    "    svm.fit(x_train, y_train)\n",
    "    train_yhat = svm.predict(x_train)\n",
    "    train_f1_score = f1_score(y_train, train_yhat)\n",
    "    test_yhat = svm.predict(x_test)\n",
    "    test_f1_score = f1_score(y_test, test_yhat)\n",
    "    train_f1_scores.append(train_f1_score)\n",
    "    test_f1_scores.append(test_f1_score)\n",
    "    train_yhat = None \n",
    "    test_yhat = None \n",
    "    x_train = None \n",
    "    x_test = None \n",
    "    y_train = None \n",
    "    y_test = None \n",
    "    print(gc.collect())\n",
    "    print(gc.collect())\n",
    "    print(gc.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.6040131214586973,\n",
       " 0.6044318917828436,\n",
       " 0.6028393758066408,\n",
       " 0.6017199906337144,\n",
       " 0.6025703977284858,\n",
       " 0.6025582311780431,\n",
       " 0.6019121193367336,\n",
       " 0.6037341522450764,\n",
       " 0.6039779146858811,\n",
       " 0.6026827160098601]"
      ]
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "train_f1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.5795683453237411,\n",
       " 0.5768404608474907,\n",
       " 0.5851074077641846,\n",
       " 0.5889167793010234,\n",
       " 0.5855556610040809,\n",
       " 0.5860230687215275,\n",
       " 0.5929878048780488,\n",
       " 0.5837025621267579,\n",
       " 0.5803741886216113,\n",
       " 0.5785455239549532]"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "test_f1_scores"
   ]
  },
  {
   "source": [
    "## Testset write"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 522449 entries, 0 to 522448\nData columns (total 2 columns):\n #   Column               Non-Null Count   Dtype \n---  ------               --------------   ----- \n 0   qid                  522449 non-null  object\n 1   preprocessed_joined  522449 non-null  object\ndtypes: object(2)\nmemory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "sparse_test_x = vectorizer.transform(test_dset_df[\"preprocessed_joined\"])\n",
    "test_yhat = svm.predict(sparse_test_x)\n",
    "output_df = test_dset_df.copy()\n",
    "output_df.info()\n",
    "output_df[\"preprocessed_joined\"] = test_yhat\n",
    "output_df = output_df.rename(columns={\"qid\":\"qid\", \"preprocessed_joined\":\"target\"})\n",
    "output_df.target = output_df.target.apply(round)\n",
    "output_df.to_csv(\"./outputs/2020_10_19_a_testset_output.csv\", index=False)\n"
   ]
  }
 ]
}