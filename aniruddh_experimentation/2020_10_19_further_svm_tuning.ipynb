{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit760f76561f6442a8b7e1ff17f4562bdb",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Further SVM Tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports and preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "train_dset_df = pd.read_csv(\"2020_10_19_train_dset_df_nostem_nostoprem.csv\")\n",
    "test_dset_df = pd.read_csv(\"2020_10_19_test_dset_df_nostem_nostoprem.csv\")\n",
    "train_dset_df[\"preprocessed_joined\"].fillna(\"\", inplace=True)\n",
    "test_dset_df[\"preprocessed_joined\"].fillna(\"\", inplace=True)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_dset_df[\"preprocessed_joined\"])\n",
    "sparse_train_x = vectorizer.transform(train_dset_df[\"preprocessed_joined\"])\n",
    "sparse_test_x  = vectorizer.transform(test_dset_df[\"preprocessed_joined\"])\n",
    "train_dset_y = train_dset_df[\"target\"].to_numpy()\n",
    "\n"
   ]
  },
  {
   "source": [
    "## LinearSVC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearSVC(C=0.0125, class_weight={0: 1, 1: 3.35})"
      ]
     },
     "metadata": {},
     "execution_count": 334
    }
   ],
   "source": [
    "svm = LinearSVC(penalty=\"l2\",dual=True,class_weight={0:1,1:3.35}, C=0.0125)\n",
    "svm.fit(sparse_train_x, train_dset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6504465956079168"
      ]
     },
     "metadata": {},
     "execution_count": 326
    }
   ],
   "source": [
    "train_dset_yhat = svm.predict(sparse_train_x)\n",
    "f1_score(train_dset_y, train_dset_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "21883 14552\n735222 48451\n"
     ]
    }
   ],
   "source": [
    "train_dset_df[\"yhat\"] = train_dset_yhat\n",
    "wrongs = train_dset_df[train_dset_df[\"target\"] != train_dset_df[\"yhat\"]]\n",
    "print(len(wrongs.groupby(by=\"target\").get_group(0)),len(wrongs.groupby(by=\"target\").get_group(1)))\n",
    "print(len(train_dset_df.groupby(by=\"target\").get_group(0)), len(train_dset_df.groupby(by=\"target\").get_group(1)))"
   ]
  },
  {
   "source": [
    "## Cross validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 329
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfcv = KFold(n_splits=10, shuffle=True)\n",
    "train_f1_scores = []\n",
    "test_f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAINING AGAIN. 0\n",
      "Zeros wrong, ones wrong in test =  2202 1712\n",
      "Test f1 score: 0.6165752351097179\n",
      "Test precision score: 0.588334268087493\n",
      "Recall score: 0.6476641284214859\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 1\n",
      "Zeros wrong, ones wrong in test =  2361 1674\n",
      "Test f1 score: 0.6120565330256706\n",
      "Test precision score: 0.5741341991341992\n",
      "Recall score: 0.6553428042001236\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 2\n",
      "Zeros wrong, ones wrong in test =  2266 1687\n",
      "Test f1 score: 0.6215414073719483\n",
      "Test precision score: 0.5888969521044993\n",
      "Recall score: 0.6580174336103791\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 3\n",
      "Zeros wrong, ones wrong in test =  2321 1559\n",
      "Test f1 score: 0.6137766275134381\n",
      "Test precision score: 0.5705033308660251\n",
      "Recall score: 0.6641533821628608\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 4\n",
      "Zeros wrong, ones wrong in test =  2337 1651\n",
      "Test f1 score: 0.6193930139339568\n",
      "Test precision score: 0.5813328556073092\n",
      "Recall score: 0.6627859477124183\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 5\n",
      "Zeros wrong, ones wrong in test =  2291 1618\n",
      "Test f1 score: 0.6165015206514274\n",
      "Test precision score: 0.5783176882017301\n",
      "Recall score: 0.6600840336134454\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 6\n",
      "Zeros wrong, ones wrong in test =  2338 1681\n",
      "Test f1 score: 0.6122527737578389\n",
      "Test precision score: 0.5757575757575758\n",
      "Recall score: 0.6536876802637\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 7\n",
      "Zeros wrong, ones wrong in test =  2278 1682\n",
      "Test f1 score: 0.6165020337013365\n",
      "Test precision score: 0.5828602819996338\n",
      "Recall score: 0.6542651593011305\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 8\n",
      "Zeros wrong, ones wrong in test =  2334 1734\n",
      "Test f1 score: 0.6074116965836712\n",
      "Test precision score: 0.5741652983032294\n",
      "Recall score: 0.6447449293177627\n",
      "0\n",
      "0\n",
      "0\n",
      "TRAINING AGAIN. 9\n",
      "Zeros wrong, ones wrong in test =  2235 1726\n",
      "Test f1 score: 0.616070563148202\n",
      "Test precision score: 0.5871051173101792\n",
      "Recall score: 0.648042414355628\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for train_index, test_index in kfcv.split(sparse_train_x):\n",
    "    print(\"TRAINING AGAIN.\", i)\n",
    "    i+=1\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    x_train, x_test = sparse_train_x[train_index], sparse_train_x[test_index]\n",
    "    y_train, y_test = train_dset_y[train_index], train_dset_y[test_index]\n",
    "    svm.fit(x_train, y_train)\n",
    "    train_yhat = svm.predict(x_train)\n",
    "    train_f1_score = f1_score(y_train, train_yhat)\n",
    "    test_yhat = svm.predict(x_test)\n",
    "    test_f1_score = f1_score(y_test, test_yhat)\n",
    "    n_y_one_and_yhat_zero = np.sum(np.logical_and(y_test == 1, test_yhat == 0).astype(int))\n",
    "    n_y_zero_and_yhat_one = np.sum(np.logical_and(y_test == 0, test_yhat == 1).astype(int))\n",
    "    print(\"Zeros wrong, ones wrong in test = \", n_y_zero_and_yhat_one,n_y_one_and_yhat_zero)\n",
    "    print(\"Test f1 score:\", test_f1_score)\n",
    "    print(\"Test precision score:\", precision_score(y_test, test_yhat))\n",
    "    print(\"Recall score:\", recall_score(y_test, test_yhat))\n",
    "    train_f1_scores.append(train_f1_score)\n",
    "    test_f1_scores.append(test_f1_score)\n",
    "    train_yhat = None \n",
    "    test_yhat = None \n",
    "    x_train = None \n",
    "    x_test = None \n",
    "    y_train = None \n",
    "    y_test = None \n",
    "    print(gc.collect())\n",
    "    print(gc.collect())\n",
    "    print(gc.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.6523289074840969,\n",
       " 0.6516767560295954,\n",
       " 0.6506225131562059,\n",
       " 0.6518062048448788,\n",
       " 0.650933804248943,\n",
       " 0.6507430884781336,\n",
       " 0.6511568288149716,\n",
       " 0.6511399538895055,\n",
       " 0.6521511634115348,\n",
       " 0.6512646797961126]"
      ]
     },
     "metadata": {},
     "execution_count": 332
    }
   ],
   "source": [
    "train_f1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.6165752351097179,\n",
       " 0.6120565330256706,\n",
       " 0.6215414073719483,\n",
       " 0.6137766275134381,\n",
       " 0.6193930139339568,\n",
       " 0.6165015206514274,\n",
       " 0.6122527737578389,\n",
       " 0.6165020337013365,\n",
       " 0.6074116965836712,\n",
       " 0.616070563148202]"
      ]
     },
     "metadata": {},
     "execution_count": 333
    }
   ],
   "source": [
    "test_f1_scores                                                                  "
   ]
  },
  {
   "source": [
    "## Testset write"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 522449 entries, 0 to 522448\nData columns (total 2 columns):\n #   Column               Non-Null Count   Dtype \n---  ------               --------------   ----- \n 0   qid                  522449 non-null  object\n 1   preprocessed_joined  522449 non-null  object\ndtypes: object(2)\nmemory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "sparse_test_x = vectorizer.transform(test_dset_df[\"preprocessed_joined\"])\n",
    "test_yhat = svm.predict(sparse_test_x)\n",
    "output_df = test_dset_df.copy()\n",
    "output_df.info()\n",
    "output_df[\"preprocessed_joined\"] = test_yhat\n",
    "output_df = output_df.rename(columns={\"qid\":\"qid\", \"preprocessed_joined\":\"target\"})\n",
    "output_df.target = output_df.target.apply(round)\n",
    "output_df.to_csv(\"./outputs/2020_10_28_a_testset_output.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}