{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit760f76561f6442a8b7e1ff17f4562bdb",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Various methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports and preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "train_dset_df = pd.read_csv(\"2020_10_19_train_dset_df_nostem_nostoprem.csv\")\n",
    "test_dset_df = pd.read_csv(\"2020_10_19_test_dset_df_nostem_nostoprem.csv\")\n",
    "train_dset_df[\"preprocessed_joined\"].fillna(\"\", inplace=True)\n",
    "test_dset_df[\"preprocessed_joined\"].fillna(\"\", inplace=True)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_dset_df[\"preprocessed_joined\"])\n",
    "sparse_train_x = vectorizer.transform(train_dset_df[\"preprocessed_joined\"])\n",
    "sparse_test_x  = vectorizer.transform(test_dset_df[\"preprocessed_joined\"])\n",
    "train_dset_y = train_dset_df[\"target\"].to_numpy()\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Metricsifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, plot_confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(model, X, y):\n",
    "    yhat = model.predict(X)\n",
    "    print(\"F1 score:\", f1_score(y, yhat))\n",
    "    print(\"Precision:\", precision_score(y, yhat))\n",
    "    print(\"Recall:\", recall_score(y, yhat))\n",
    "    print(\"Confusion matrix:\")\n",
    "    plot_confusion_matrix(model, X, y)\n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "## Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "source": [
    "0.60 crossval F1 score <only TFIDF>\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy=0.21)\n",
    "\n",
    "svm = LinearSVC(penalty=\"l2\",dual=True,class_weight={0:1,1:1}, C=0.003)\n",
    "\n",
    "model = make_pipeline(ros, svm)\n",
    "\n",
    "---------------------------------------\n",
    "\n",
    "0.58 crossval F1 score <only TFIDF>\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy=0.18)\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=200, verbose=3, learning_rate=0.7)\n",
    "\n",
    "model = make_pipeline(ros, gbc)\n",
    "\n",
    "\n",
    "--------------------------------------\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(sampling_strategy=0.18)\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=200, verbose=3, learning_rate=0.7)\n",
    "\n",
    "model = make_pipeline(ros, gbc)"
   ]
  },
  {
   "source": [
    "## Cross validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAINING AGAIN. 0\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7307           43.57m\n",
      "         2           0.6998           43.19m\n",
      "         3           0.6675           43.09m\n",
      "         4           0.6449           43.31m\n",
      "         5           0.6319           43.74m\n",
      "         6           0.6217           43.70m\n",
      "         7           0.6068           43.86m\n",
      "         8           0.5965           43.79m\n",
      "         9           0.5890           43.78m\n",
      "        10           0.5819           43.63m\n",
      "        11           0.5763           43.50m\n",
      "        12           0.5712           43.34m\n",
      "        13           0.5664           43.19m\n",
      "        14           0.5624           43.04m\n",
      "        15           0.5585           42.85m\n",
      "        16           0.5536           42.67m\n",
      "        17           0.5498           42.47m\n",
      "        18           0.5465           42.27m\n",
      "        19           0.5433           42.07m\n",
      "        20           0.5400           41.86m\n",
      "        21           0.5375           41.65m\n",
      "        22           0.5350           41.40m\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "kfcv = KFold(n_splits=10, shuffle=True)\n",
    "for train_index, test_index in kfcv.split(sparse_train_x):\n",
    "    print(\"TRAINING AGAIN.\", i)\n",
    "    i+=1\n",
    "    trainset_X, testset_X  = sparse_train_x[train_index], sparse_train_x[test_index]\n",
    "    trainset_Y, testset_Y  = train_dset_y[train_index], train_dset_y[test_index]\n",
    "    model.fit(trainset_X, trainset_Y)\n",
    "    print(\"\\n\\nTraining:\")\n",
    "    summarize(model, trainset_X, trainset_Y)\n",
    "    print(\"\\nTesting:\")\n",
    "    summarize(model, testset_X, testset_Y)\n",
    "    print(\"---------------------------------\")\n",
    "\n",
    "    "
   ]
  }
 ]
}