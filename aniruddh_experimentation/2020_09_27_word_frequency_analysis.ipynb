{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit760f76561f6442a8b7e1ff17f4562bdb",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Further data cleaning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DSET_FOLDER_PATH = './dataset/quora/'\n",
    "GLOVE_FOLDER_PATH = './embeddings/glove/'\n",
    "CORPUS_FOLDER_PATH = './corpi/'\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt  \n",
    "import wordcloud as wc \n",
    "import seaborn as sns \n",
    "import nltk\n",
    "import re\n",
    "import contractions\n",
    "import symspellpy\n",
    "train_dset_df = pd.read_csv(DSET_FOLDER_PATH + \"train.csv\")\n",
    "from tqdm import tqdm \n",
    "tqdm.pandas()"
   ]
  },
  {
   "source": [
    "## 2. Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 783673/783673 [00:27<00:00, 28553.68it/s]\n"
    }
   ],
   "source": [
    "# import utils.PreprocessingEmbedding20200928 as pped \n",
    "# preprocessor = pped.Preprocessor()\n",
    "# train_dset_df[\"preprocessed\"] = train_dset_df[\"question_text\"].progress_apply(preprocessor.preprocess)\n",
    "\n",
    "# train_dset_df[\"preprocessed_joined\"] = train_dset_df.preprocessed.progress_apply(lambda x: \" \".join(x))\n",
    "# string_of_all_words = train_dset_df.preprocessed_joined.to_string()\n",
    "# list_of_all_words = string_of_all_words.split()\n",
    "# set_of_all_words = set(list_of_all_words)\n",
    "# len(set_of_all_words)\n",
    "# string_of_all_words = \" \".join(sorted(list(set_of_all_words)))\n",
    "# file = open(\"unique_words.txt\", \"w\")\n",
    "# file.write(string_of_all_words)\n",
    "# file.close()"
   ]
  },
  {
   "source": [
    "# Notes based on unique_words.txt\n",
    "\n",
    "unique_words.txt illustrates important things: \n",
    "\n",
    "a. Numbers must be dropped.\n",
    "\n",
    "b. Misspelled words must be dealt with.\n",
    "\n",
    "c. Words with special-character prefixes and suffixes (ellipsis etc.)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}